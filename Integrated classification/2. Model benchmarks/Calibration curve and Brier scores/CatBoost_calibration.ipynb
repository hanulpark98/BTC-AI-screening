{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2c693bd4-d793-4226-b4c6-ff50bdb081d0",
   "metadata": {},
   "source": [
    "Package Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a18aa949-6a6c-43bc-abea-88ee03641794",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import gc\n",
    "import shap\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score,classification_report, f1_score, roc_curve, auc, recall_score, confusion_matrix, brier_score_loss\n",
    "from sklearn.calibration import calibration_curve\n",
    "from sklearn.model_selection import train_test_split\n",
    "from catboost import CatBoostClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6251be2b-2483-480e-9bdc-22620959381f",
   "metadata": {},
   "source": [
    "User Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b48b21de-6ffc-4a44-847b-34ee41109194",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify your datset location and label column name\n",
    "dataset = \"Your dataset location\"\n",
    "label_column = 'Your label column name'\n",
    "\n",
    "# Assign your optimized hyperparameters for your XGBoost model\n",
    "params = {'booster': 'dart', 'max_depth': 9, 'learning_rate': 0.16757526880337048, 'n_estimators': 271, 'min_child_weight': 10, 'subsample': 0.6462807491201441, 'colsample_bytree': 0.899034861491886, 'gamma': 0.5134323315817606, 'lambda': 0.33831616398436576, 'alpha': 0.11680506336726469}\n",
    "\n",
    "# Specify the number of dataset random state splits for evaluation of calibration scores\n",
    "random_state_num = 30"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e9f911c-dba7-4ae7-bf51-ac4008e895c5",
   "metadata": {},
   "source": [
    "Data & Function Preperation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c769cbd-c7d3-44db-a217-a0f7d198ee95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset using Pandas\n",
    "df = pd.read_excel(dataset)\n",
    "\n",
    "# Specify the target column name\n",
    "target_name = 'Cancer Label'\n",
    "\n",
    "X = df.drop(columns=[label_column])\n",
    "y = df[label_column]\n",
    "\n",
    "# Encode categorical variables if needed\n",
    "for column in X.select_dtypes(include=['object']).columns:\n",
    "    le = LabelEncoder()\n",
    "    X[column] = le.fit_transform(X[column])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbb2d1c7-3774-449d-8103-41922de5c4d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model_across_splits(model, X, y, n_splits=30, test_size=0.2):\n",
    "    \n",
    "    all_test_probs = []\n",
    "    all_test_true = []\n",
    "    split_results = []\n",
    "    \n",
    "    for random_state in tqdm(range(n_splits), desc=\"Evaluating model across splits\", ncols=100):\n",
    "        # Split data\n",
    "        X_train, X_test, y_train, y_test = train_test_split(\n",
    "            X, y, test_size=test_size, random_state=random_state\n",
    "        )\n",
    "        \n",
    "        # Train model\n",
    "        model.fit(X_train, y_train)\n",
    "        \n",
    "        # Get predictions\n",
    "        test_probs = model.predict_proba(X_test)[:, 1]\n",
    "        \n",
    "        # Store results\n",
    "        all_test_probs.extend(test_probs)\n",
    "        all_test_true.extend(y_test)\n",
    "        \n",
    "        # Store individual split results\n",
    "        split_results.append({\n",
    "            'random_state': random_state,\n",
    "            'test_probs': test_probs,\n",
    "            'test_true': y_test,\n",
    "            'brier_score': brier_score_loss(y_test, test_probs)\n",
    "        })\n",
    "    \n",
    "    return {\n",
    "        'pooled_probs': np.array(all_test_probs),\n",
    "        'pooled_true': np.array(all_test_true),\n",
    "        'split_results': split_results\n",
    "    }\n",
    "\n",
    "\n",
    "\n",
    "def plot_pooled_calibration(results, n_splits=30):\n",
    "    fig, ax = plt.subplots(figsize=(8, 6))\n",
    "\n",
    "    # Pooled Calibration Curve\n",
    "    prob_true, prob_pred = calibration_curve(\n",
    "        results['pooled_true'],\n",
    "        results['pooled_probs'],\n",
    "        n_bins=10,\n",
    "        strategy='quantile'  # Use quantile binning for more reliable estimates\n",
    "    )\n",
    "\n",
    "    ax.plot([0, 1], [0, 1], 'k--', label='Perfectly calibrated')\n",
    "    ax.plot(prob_pred, prob_true, 's-', label='Model')\n",
    "\n",
    "    ax.set_xlabel('Mean predicted probability', fontsize=18)\n",
    "    ax.set_ylabel('Empirical probability', fontsize=18)\n",
    "    ax.set_title(f'Pooled Calibration Curve\\n(from {n_splits} random splits)', fontsize=18)\n",
    "    ax.tick_params(axis='both', labelsize=16)\n",
    "    ax.legend(loc='lower right', fontsize=16)\n",
    "    ax.grid(True)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    return fig, ax\n",
    "\n",
    "def analyze_brier_scores(results):\n",
    "    # Extract split Brier scores from the precomputed results\n",
    "    brier_scores = [split['brier_score'] for split in results['split_results']]\n",
    "\n",
    "    # Convert to numpy array for easier analysis\n",
    "    brier_scores = np.array(brier_scores)\n",
    "\n",
    "    # Calculate statistical measures\n",
    "    stats_summary = {\n",
    "        'mean': np.mean(brier_scores),\n",
    "        'std': np.std(brier_scores),\n",
    "        'median': np.median(brier_scores),\n",
    "        'ci_95': stats.norm.interval(0.95, loc=np.mean(brier_scores), scale=stats.sem(brier_scores))\n",
    "    }\n",
    "\n",
    "    # Create visualization\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(19, 6))\n",
    "\n",
    "    # Plot 1: Brier scores across trials\n",
    "    ax1.plot(range(1, len(brier_scores) + 1), brier_scores, 'b-', label='Brier Score')\n",
    "    ax1.axhline(y=stats_summary['mean'], color='r', linestyle='--', label=f\"Mean: {stats_summary['mean']:.4f}\")\n",
    "    ax1.fill_between(range(1, len(brier_scores) + 1),\n",
    "                     stats_summary['ci_95'][0], stats_summary['ci_95'][1],\n",
    "                     alpha=0.2, color='gray', label='95% CI')\n",
    "    ax1.set_xlabel('Random State Trial', fontsize=15)\n",
    "    ax1.set_ylabel('Brier Score', fontsize=18)\n",
    "    ax1.tick_params(axis='y', labelsize=15)\n",
    "    ax1.set_title('Brier Scores Across Random State Trials', fontsize=18)\n",
    "    ax1.legend(fontsize=16)\n",
    "    ax1.grid(True)\n",
    "\n",
    "    # Plot 2: Distribution of Brier scores\n",
    "    sns.histplot(brier_scores, kde=True, ax=ax2)\n",
    "    ax2.axvline(x=stats_summary['mean'], color='r', linestyle='--', label=f\"Mean: {stats_summary['mean']:.4f}\")\n",
    "    ax2.set_xlabel('Brier Score')\n",
    "    ax2.set_ylabel('Count')\n",
    "    ax2.set_title('Distribution of Brier Scores')\n",
    "    ax2.legend()\n",
    "\n",
    "    # Print detailed statistics\n",
    "    print(\"\\nBrier Score Statistics:\")\n",
    "    print(f\"Mean: {stats_summary['mean']:.4f}\")\n",
    "    print(f\"Standard Deviation: {stats_summary['std']:.4f}\")\n",
    "    print(f\"Median: {stats_summary['median']:.4f}\")\n",
    "    print(f\"95% Confidence Interval: [{stats_summary['ci_95'][0]:.4f}, {stats_summary['ci_95'][1]:.4f}]\")\n",
    "\n",
    "    return brier_scores, stats_summary, (fig, (ax1, ax2))\n",
    "\n",
    "\n",
    "def initiate_analysis():\n",
    "\n",
    "    # Create and evaluate model\n",
    "    model = CatBoostClassifier(**params)\n",
    "    results = evaluate_model_across_splits(model, X, y, n_splits=30)\n",
    "\n",
    "    return results\n",
    "\n",
    "# Example usage\n",
    "def brier_scores(results):\n",
    "\n",
    "    # Plot results for brier scores\n",
    "    brier_scores, stats, (fig, axes) = analyze_brier_scores(results)\n",
    "    plt.show()\n",
    "\n",
    "# Example usage\n",
    "def calibration_plot(results):\n",
    "\n",
    "    # Plot results\n",
    "    fig, axes = plot_pooled_calibration(results)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8928ccd-3572-426c-b70c-0dce1873d417",
   "metadata": {},
   "source": [
    "Initiate calibration analysis "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f67e73c-f480-41b4-b5b6-e9f04c94b343",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = initiate_analysis()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6259ed37-6efa-4749-8198-c8cdf7b8534d",
   "metadata": {},
   "source": [
    "Check calibration curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f72a931a-bd8e-471f-a1f7-9b85981cc22d",
   "metadata": {},
   "outputs": [],
   "source": [
    "brier_scores(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ad1c070-e42b-473b-9e73-19e59ef74d70",
   "metadata": {},
   "source": [
    "Check Brier scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbc9eb4f-390b-4b9e-ad5c-23eb289c360e",
   "metadata": {},
   "outputs": [],
   "source": [
    "calibration_plot(results)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
